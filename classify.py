import json
import time
import re
import pandas as pd
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager

REAL_ESTATE_KEYWORDS = [
    "b·∫•t ƒë·ªông s·∫£n", "nh√† ƒë·∫•t", "cƒÉn h·ªô", "chung c∆∞", "mua nh√†", "b√°n nh√†", "t∆∞ v·∫•n nh√† ƒë·∫•t",
    "vinhomes", "vinhomes grand park", "ƒë·∫ßu t∆∞ bƒës", "m√¥i gi·ªõi nh√† ƒë·∫•t", "b√°n",
    "gi√° t·ªët", "gi·ªØ ch·ªó", "ch·ªß ƒë·∫ßu t∆∞", "m·ªü b√°n", "thanh to√°n", "chi·∫øt kh·∫•u", "sang nh∆∞·ª£ng",
    "shophouse", "bi·ªát th·ª±", "ƒë·∫•t n·ªÅn", "d·ª± √°n", "gi·ªè h√†ng", "view s√¥ng", "full n·ªôi th·∫•t",
    "h·ª£p ƒë·ªìng mua b√°n", "booking", "s·ªü h·ªØu l√¢u d√†i", "ph√°p l√Ω", "th·ªß t·ª•c", "bƒës","therainbow","theorigami", 
    "thebeverlyslolari","thebeverly","theopusone","mastericentrepoint","lumiereboulevard","themanhattan","themahattanglory","thegloryheight"
]

AGENT_KEYWORDS = [
    "chuy√™n vi√™n", "t∆∞ v·∫•n", "sale", "saler", "m√¥i gi·ªõi", "chuy√™n b√°n", "nh√¢n vi√™n kinh doanh",
    "gi·ªè h√†ng", "cƒÉn n·ªôi b·ªô", "∆∞u ƒë√£i", "chi·∫øt kh·∫•u", "gi·ªØ ch·ªó", "ƒë·∫∑t c·ªçc", "ƒëƒÉng k√Ω ngay",
    "ph√≤ng kinh doanh", "li√™n h·ªá em", "call em", "inbox em", "h·ªó tr·ª£ vay", "zalo"
]

OWNER_KEYWORDS = [
    "ch√≠nh ch·ªß", "gia ƒë√¨nh", "b√°n g·∫•p", "kh√¥ng qua trung gian", "c·∫ßn ti·ªÅn", "b√°n nh√† ri√™ng",
    "nh√† m√¨nh", "t√¥i c·∫ßn b√°n", "nh√† c·ªßa t√¥i", "c·∫ßn b√°n g·∫•p"
]

REAL_ESTATE_PATTERN = re.compile(r"\b(" + "|".join(REAL_ESTATE_KEYWORDS) + r")\b", re.IGNORECASE)
AGENT_PATTERN = re.compile(r"\b(" + "|".join(AGENT_KEYWORDS) + r")\b", re.IGNORECASE)
OWNER_PATTERN = re.compile(r"\b(" + "|".join(OWNER_KEYWORDS) + r")\b", re.IGNORECASE)

def classify_user_type(texts):
    combined_text = " ".join(texts).lower()
    if re.search(AGENT_PATTERN, combined_text):
        return ("Ng∆∞·ªùi b√°n b·∫•t ƒë·ªông s·∫£n Vinhomes Grand Park", "Saler / M√¥i gi·ªõi")
    elif re.search(OWNER_PATTERN, combined_text):
        return ("Ng∆∞·ªùi b√°n b·∫•t ƒë·ªông s·∫£n Vinhomes Grand Park", "Ch√≠nh ch·ªß")
    elif re.search(REAL_ESTATE_PATTERN, combined_text):
        return ("Ng∆∞·ªùi b√°n b·∫•t ƒë·ªông s·∫£n Vinhomes Grand Park", "Kh√¥ng r√µ (ch·ªâ c√≥ t·ª´ kh√≥a BƒêS)")
    else:
        return ("Ng∆∞·ªùi mua", "")

def load_cookies(driver, cookie_file):
    try:
        with open(cookie_file, "r", encoding="utf-8") as f:
            cookies = json.load(f)
        driver.get("https://www.facebook.com")
        for cookie in cookies:
            cookie.pop("storeId", None)
            cookie.pop("id", None)
            if "sameSite" in cookie and cookie["sameSite"].lower() in ["no_restriction", "unspecified"]:
                cookie["sameSite"] = "None"
            try:
                driver.add_cookie(cookie)
            except Exception as e:
                print(f"[WARNING] Kh√¥ng th·ªÉ th√™m cookie {cookie.get('name', 'UNKNOWN')}: {e}")
        driver.refresh()
        time.sleep(3)
        if "login" in driver.current_url:
            print("[ERROR] Cookie h·∫øt h·∫°n ho·∫∑c sai! üö®")
            return False
        print("[INFO] ƒêƒÉng nh·∫≠p th√†nh c√¥ng b·∫±ng cookie! ‚úÖ")
        return True
    except Exception as e:
        print(f"[ERROR] L·ªói khi t·∫£i cookie: {e}")
        return False

def scroll_page(driver, scrolls=3):
    for _ in range(scrolls):
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
        time.sleep(3)

def get_facebook_posts(driver, profile_url):
    driver.get(profile_url)
    try:
        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.TAG_NAME, "body")))
    except:
        print(f"[ERROR] Kh√¥ng th·ªÉ t·∫£i trang {profile_url}!")
        return [], []
    scroll_page(driver)

    posts = []
    links = []
    try:
        elements = driver.find_elements(By.CSS_SELECTOR, "[data-ad-preview='message']")
        for el in elements:
            post_text = el.text.strip()
            if post_text:
                posts.append(post_text)
            try:
                link_el = el.find_element(By.XPATH, "..//ancestor::div[contains(@data-testid, 'story-subtitle')]//a")
                post_link = link_el.get_attribute("href")
                if post_link and "facebook.com" in post_link:
                    links.append(post_link)
            except:
                pass
    except Exception as e:
        print(f"[WARNING] Kh√¥ng th·ªÉ l·∫•y b√†i vi·∫øt t·ª´ {profile_url}: {e}")
    return posts, links

def get_facebook_about(driver, profile_url):
    about_url = profile_url + "/about"
    driver.get(about_url)
    try:
        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.TAG_NAME, "body")))
    except:
        print(f"[ERROR] Kh√¥ng th·ªÉ t·∫£i trang gi·ªõi thi·ªáu {about_url}!")
        return ""
    time.sleep(3)
    about_text = ""
    try:
        elements = driver.find_elements(By.CSS_SELECTOR, "div[data-visualcompletion='ignore-dynamic']")
        for el in elements:
            about_text += el.text + " "
    except Exception as e:
        print(f"[WARNING] Kh√¥ng th·ªÉ l·∫•y ph·∫ßn gi·ªõi thi·ªáu t·ª´ {about_url}: {e}")
    return about_text.strip()

def classify_accounts(excel_file, cookie_file, output_file="output1.xlsx"):
    chrome_options = webdriver.ChromeOptions()
    chrome_options.add_argument("--disable-blink-features=AutomationControlled")
    chrome_options.add_argument("--headless=new")
    chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
    chrome_options.add_experimental_option("useAutomationExtension", False)

    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=chrome_options)

    if not load_cookies(driver, cookie_file):
        driver.quit()
        raise RuntimeError("[ERROR] Kh√¥ng th·ªÉ ƒëƒÉng nh·∫≠p Facebook!")

    df = pd.read_excel(excel_file)
    urls = df["Tr√πng URL"].dropna().tolist()
    links_bai_viet_goc = df["Link B√†i Vi·∫øt"].tolist()

    results = []
    for i, url in enumerate(urls):
        print(f"[INFO] ƒêang ki·ªÉm tra: {url}...")
        posts, post_links_moi = get_facebook_posts(driver, url)
        about_text = get_facebook_about(driver, url)
        account_type, detail = classify_user_type(posts + [about_text])

        results.append({
            "Tr√πng URL": url,
            "Link B√†i Vi·∫øt": links_bai_viet_goc[i] if i < len(links_bai_viet_goc) else "",
            "Lo·∫°i t√†i kho·∫£n": account_type,
            "Ph√¢n lo·∫°i": detail
        })

    driver.quit()
    df_result = pd.DataFrame(results)
    df_result.to_excel(output_file, index=False)
    print(f"[INFO] ‚úÖ ƒê√£ l∆∞u k·∫øt qu·∫£ v√†o {output_file}")

# Ch·∫°y tool
# classify_accounts("matched_urls.xlsx", "facebook_cookies.json")
if __name__ == "__main__":
    pass