import time
import json
import cv2
import numpy as np
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from webdriver_manager.chrome import ChromeDriverManager
import pandas as pd
import os
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import requests
from collections import Counter
from selenium.webdriver.common.keys import Keys
from selenium.common.exceptions import NoSuchElementException
# C·∫•u h√¨nh Selenium (Chrome)
chrome_options = webdriver.ChromeOptions()
chrome_options.add_argument("--headless")  # Ch·∫°y n·ªÅn ƒë·ªÉ kh√¥ng m·ªü tr√¨nh duy·ªát
chrome_options.add_argument("--disable-blink-features=AutomationControlled")  # Tr√°nh b·ªã Facebook ph√°t hi·ªán
chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
chrome_options.add_experimental_option("useAutomationExtension", False)
service = Service(ChromeDriverManager().install())  # C·∫≠p nh·∫≠t ChromeDriver t·ª± ƒë·ªông
def load_cookies(driver, cookie_file):
    """T·∫£i cookie t·ª´ file JSON v√† g√°n v√†o tr√¨nh duy·ªát"""
    try:
        with open(cookie_file, "r", encoding="utf-8") as f:
            cookies = json.load(f)

        driver.get("https://www.facebook.com")
        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.TAG_NAME, "body")))

        for cookie in cookies:
            cookie.pop("storeId", None)
            cookie.pop("id", None)

            if "sameSite" in cookie and cookie["sameSite"].lower() in ["no_restriction", "unspecified"]:
                cookie["sameSite"] = "None"

            try:
                driver.add_cookie(cookie)
            except Exception as e:
                print(f"[WARNING] Kh√¥ng th·ªÉ th√™m cookie {cookie.get('name', 'UNKNOWN')}: {e}")

        print("[INFO] ƒê√£ t·∫£i cookie th√†nh c√¥ng! üî•")
        driver.refresh()
        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.TAG_NAME, "body")))

        return True
    except Exception as e:
        print(f"[ERROR] L·ªói khi t·∫£i cookie: {e}")
        return False

def login_with_cookies(driver, post_link, cookie_file="facebook_test.json"):
    """T·ª± ƒë·ªông ƒëƒÉng nh·∫≠p Facebook b·∫±ng cookie"""
    print("[INFO] ƒêang th·ª≠ ƒëƒÉng nh·∫≠p b·∫±ng cookie...")

    if not load_cookies(driver, cookie_file):
        print("[ERROR] Kh√¥ng th·ªÉ t·∫£i cookie. Vui l√≤ng ki·ªÉm tra l·∫°i!")
        return False

    driver.get(post_link)
    
    try:
        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.TAG_NAME, "body")))
    except:
        print("[ERROR] Kh√¥ng th·ªÉ t·∫£i b√†i vi·∫øt! C√≥ th·ªÉ t√†i kho·∫£n b·ªã ch·∫∑n.")
        return False

    if "login" in driver.current_url:
        print("[ERROR] Cookie h·∫øt h·∫°n ho·∫∑c sai! üö® Vui l√≤ng c·∫≠p nh·∫≠t cookie m·ªõi.")
        return False

    print("[INFO] ƒêƒÉng nh·∫≠p th√†nh c√¥ng b·∫±ng cookie! ‚úÖ")
    return True

# ƒê·ªçc danh s√°ch t√†i kho·∫£n t·ª´ file Excel
def read_accounts_from_excel(file_path):
    df = pd.read_excel(file_path)
    return df["Link User"].tolist()
def check_blur(image_url):
    try:
        resp = requests.get(image_url, stream=True)
        if resp.status_code != 200:
            print(f"[ERROR] Kh√¥ng th·ªÉ t·∫£i ·∫£nh: {image_url}")
            return False

        image = np.asarray(bytearray(resp.raw.read()), dtype="uint8")
        image = cv2.imdecode(image, cv2.IMREAD_COLOR)
        if image is None:
            print(f"[ERROR] Kh√¥ng th·ªÉ gi·∫£i m√£ ·∫£nh: {image_url}")
            return False

        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        variance = cv2.Laplacian(gray, cv2.CV_64F).var()
        return variance < 100
    except Exception as e:
        print(f"[ERROR] Kh√¥ng th·ªÉ ki·ªÉm tra ƒë·ªô m·ªù c·ªßa ·∫£nh: {e}")
        return False
    
def check_duplicate_full_names(driver):
    try:
        friend_elements = driver.find_elements(By.XPATH, "//div[contains(@class, 'friend_name')]")
        friend_names = [friend.text.strip() for friend in friend_elements if friend.text.strip()]
        
        if not friend_names:
            return 0
        
        name_counts = Counter(friend_names)
        duplicate_ratio = sum(count for count in name_counts.values() if count > 1) / len(friend_names)
        
        return -10 if duplicate_ratio > 0.3 else 0
    except Exception as e:
        print(f"[ERROR] Kh√¥ng th·ªÉ ki·ªÉm tra tr√πng l·∫∑p h·ªç t√™n: {e}")
        return 0

foreign_keywords = ["Kumar", "Singh", "Ali", "Hussain", "Patel"]

def check_foreign_friends(driver):
    try:
        friend_elements = driver.find_elements(By.XPATH, "//div[contains(@class, 'friend_name')]")
        friend_names = [friend.text.strip().lower() for friend in friend_elements if friend.text.strip()]
        
        if not friend_names:
            return 0
        
        foreign_friends = sum(1 for name in friend_names if any(keyword.lower() in name for keyword in foreign_keywords))
        foreign_ratio = foreign_friends / len(friend_names)
        
        return -10 if foreign_ratio > 0.5 else 0
    except Exception as e:
        print(f"[ERROR] Kh√¥ng th·ªÉ ki·ªÉm tra b·∫°n b√® n∆∞·ªõc ngo√†i: {e}")
        return 0

def check_interactions(driver):
    try:
        posts = driver.find_elements(By.XPATH, "//div[@role='article']")
        if not posts:
            return -10  # Kh√¥ng c√≥ b√†i vi·∫øt ‚Üí tr·ª´ ƒëi·ªÉm

        total_likes = 0
        total_comments = 0 

        for post in posts[:5]:  # Ki·ªÉm tra 5 b√†i vi·∫øt g·∫ßn nh·∫•t
            like_elements = post.find_elements(By.XPATH, ".//span[contains(@aria-label, 'like') or contains(@innerText, 'likes')]")
            comment_elements = post.find_elements(By.XPATH, ".//span[contains(@aria-label, 'comment') or contains(@innerText, 'comments')]")

            if like_elements:
                total_likes += int(''.join(filter(str.isdigit, like_elements[0].get_attribute("innerText"))))
            if comment_elements:
                total_comments += int(''.join(filter(str.isdigit, comment_elements[0].get_attribute("innerText"))))

        if total_likes + total_comments < 5:
            return -10  # √çt h∆°n 5 l∆∞·ª£t t∆∞∆°ng t√°c ‚Üí tr·ª´ ƒëi·ªÉm
        return 0
    except Exception as e:
        print(f"[ERROR] Kh√¥ng th·ªÉ ki·ªÉm tra t∆∞∆°ng t√°c: {e}")
        return 0

def count_photos(driver):
    """ƒê·∫øm s·ªë l∆∞·ª£ng ·∫£nh tr√™n trang Facebook Photos b·∫±ng c√°ch cu·ªôn xu·ªëng"""
    photos_count = 0
    try:
        # T√¨m v√† click v√†o link Photos
        photos_link = driver.find_element(By.XPATH, "//a[contains(@href, 'photos')]")
        photos_link.click()
        time.sleep(3)  # Ch·ªù trang load

        # L·∫•y ph·∫ßn th√¢n c·ªßa trang ƒë·ªÉ cu·ªôn
        body = driver.find_element(By.TAG_NAME, "body")

        last_count = 0
        retries = 3  # S·ªë l·∫ßn th·ª≠ n·∫øu kh√¥ng c√≥ ·∫£nh m·ªõi

        while retries > 0:
            # L·∫•y danh s√°ch ·∫£nh hi·ªán t·∫°i
            photos_elements = driver.find_elements(By.XPATH, "//img[contains(@src, 'scontent')]")
            photos_count = len(photos_elements)

            if photos_count > last_count:
                last_count = photos_count
                retries = 3  # Reset l·∫°i retries n·∫øu c√≥ ·∫£nh m·ªõi
            else:
                retries -= 1  # Gi·∫£m s·ªë l·∫ßn th·ª≠ n·∫øu kh√¥ng c√≥ ·∫£nh m·ªõi

            # Cu·ªôn xu·ªëng ƒë·ªÉ t·∫£i th√™m ·∫£nh
            body.send_keys(Keys.END)
            time.sleep(2)  # Ch·ªù ·∫£nh t·∫£i

    except Exception as e:
        print(f"[ERROR] Kh√¥ng th·ªÉ ki·ªÉm tra s·ªë ·∫£nh: {e}")

    print(f"[INFO] S·ªë ·∫£nh: {photos_count}")
    return photos_count


def check_account(driver, url):
    driver.get(url)
    time.sleep(5)
    try:
        # 1. L·∫•y t√™n v√† check profile kh√≥a
        name = driver.find_element(By.TAG_NAME, "h1").text.strip()
        locked_profile = (
            "locked his profile" in driver.page_source
            or "has locked their profile" in driver.page_source
            or "ƒë√£ kh√≥a b·∫£o v·ªá trang c√° nh√¢n" in driver.page_source
        )
        if locked_profile:
            return {"url": url, "name": name, "locked_profile": True, "score": 0}
        
        mutual_count = 0
        try:
            mutual_elem = driver.find_element(
                By.XPATH,
                "//a[contains(@href, '/friends_mutual/')]"
            )
            mutual_text = mutual_elem.text
            digits_m = ''.join(filter(str.isdigit, mutual_text))
            mutual_count = int(digits_m) if digits_m else 0
        except NoSuchElementException:
            mutual_count = 0
        print(f"[INFO] S·ªë b·∫°n chung: {mutual_count}")
        details = {
            "Mutualfriends": mutual_count,
            "HasStories": bool(driver.find_elements(By.XPATH, "//a[contains(@href, '/stories/')]")),
            "Email_verified": bool(driver.find_elements(By.XPATH,"//a[starts-with(@href,'mailto:')] | //span[contains(text(),'@') and contains(text(),'.')]")),
            "Youtube": bool(driver.find_elements(By.XPATH, "//a[contains(@href, 'youtube.com')]")),
            "Twitter_X": bool(driver.find_elements(By.XPATH, "//a[contains(@href, 'twitter.com') or contains(@href, 'x.com')]")),
            "Linktree": bool(driver.find_elements(By.XPATH, "//a[contains(@href, 'linktr.ee')]")),
            "Behance": bool(driver.find_elements(By.XPATH, "//a[contains(@href, 'behance.net')]")),
            "Medium": bool(driver.find_elements(By.XPATH, "//a[contains(@href, 'medium.com')]")),
            "Discord": bool(driver.find_elements(By.XPATH, "//a[contains(@href, 'discord.gg') or contains(@href, 'discord.com')]")),
            "Telegram": bool(driver.find_elements(By.XPATH, "//a[contains(@href, 't.me')]")),
            "Reddit": bool(driver.find_elements(By.XPATH, "//a[contains(@href, 'reddit.com')]")),
            "SoundCloud": bool(driver.find_elements(By.XPATH, "//a[contains(@href, 'soundcloud.com')]")),
            "Work": bool(driver.find_elements(By.XPATH, "//span[contains(text(), 'Works at') or contains(text(), 'L√†m vi·ªác t·∫°i')]") ),
            # "Education": bool(driver.find_elements(By.XPATH, "//span[contains(text(), 'Studied at') or contains(text(), 'H·ªçc t·∫°i')]") ),
            "Lives": bool(driver.find_elements(By.XPATH, "//span[contains(text(), 'Lives in') or contains(text(), 'S·ªëng t·∫°i')]") ),
            "Birthday": bool(driver.find_elements(By.XPATH, "//span[contains(text(), 'Born on') or contains(text(), 'Sinh nh·∫≠t')]") ),
            "Checkins": bool(driver.find_elements(By.XPATH, "//span[contains(text(), 'Check-ins') or contains(text(), 'ƒê√£ gh√© thƒÉm')]") ),
            "Instagram": bool(driver.find_elements(By.XPATH, "//a[contains(@href, 'instagram.com')]") ),
            "Phone_verified": bool(driver.find_elements(By.XPATH, "//span[contains(text(), 'Phone number') or contains(text(), 'S·ªë ƒëi·ªán tho·∫°i')]") ),
            "Goes_to": bool(driver.find_elements(By.XPATH, "//span[contains(text(), 'Goes to') or contains(text(), 'H·ªçc ·ªü')]") ),
            "Studied": bool(driver.find_elements(By.XPATH, "//span[contains(text(), 'Studied') or contains(text(), 'H·ªçc')]") ),
            "Went_to": bool(driver.find_elements(By.XPATH, "//span[contains(text(), 'Went to') or contains(text(), 'ƒê√£ h·ªçc t·∫°i')]") ),
            "Chu_tich_at": bool(driver.find_elements(By.XPATH, "//span[contains(text(), 'Chu tich at') or contains(text(), 'Chu tich t·∫°i')]") ),
            "T√¥ng_giam_ƒë√¥c_at": bool(driver.find_elements(By.XPATH, "//span[contains(text(), 'T√¥ng giam ƒë√¥c at') or contains(text(), 'T√¥ng giam ƒë√¥c t·∫°i')]") ),
            "Relationship": bool(driver.find_elements(By.XPATH, "//span[contains(text(), 'In a relationship') or contains(text(), 'ƒêang h·∫πn h√≤') or contains(text(), 'Single') or contains(text(), 'ƒê·ªôc th√¢n') or contains(text(), 'Married') or contains(text(), 'ƒê√£ k·∫øt h√¥n')]") ),
            "Followed by": bool(driver.find_elements(By.XPATH, "//span[contains(text(), 'Followed by') or contains(text(), 'theo d√µi')]") ),
            "followers": bool(driver.find_elements(By.XPATH,"//a[contains(@href, '/followers/') and (contains(., 'followers') or contains(., 'ng∆∞·ªùi theo d√µi'))]")),
            "following": bool(driver.find_elements(By.XPATH,"//a[contains(@href, '/following/') and (contains(., 'following') or contains(., 'ƒëang theo d√µi'))]")),
            "From": bool(driver.find_elements(By.XPATH, "//span[contains(text(), 'From') or contains(text(), 'ƒê·∫øn T·ª´')]") ),
            "Manager_at": bool(driver.find_elements(By.XPATH, "//span[contains(text(), 'Manager at') or contains(text(), 'Manager t·∫°i')]") ),
            "Joined_on": bool(driver.find_elements(By.XPATH, "//span[contains(text(), 'Joined on') or contains(text(), 'Tham gia v√†o')]") ),
            "Github": bool(driver.find_elements(By.XPATH, "//a[contains(@href, 'github.com')]") ),
            "TikTok": bool(driver.find_elements(By.XPATH, "//a[contains(@href, 'tiktok.com')]") ),
            "Vercel": bool(driver.find_elements(By.XPATH, "//a[contains(@href, 'vercel.app')]") ),
            "PlayerDuo": bool(driver.find_elements(By.XPATH, "//a[contains(@href, 'playerduo.com')]") ),
            "Threads": bool(driver.find_elements(By.XPATH, "//a[contains(@href, 'threads.net')]") ),
            "Spotify": bool(driver.find_elements(By.XPATH, "//a[contains(@href, 'open.spotify.com')]") )
        }
        youtube_elements = driver.find_elements(By.XPATH, "//a[contains(@href, 'youtube.com')]")
        print(f"[DEBUG] YouTube Elements Found: {len(youtube_elements)}")
        youtube_link = youtube_elements[0].get_attribute("href") if youtube_elements else None
        print(f"[DEBUG] YouTube Link: {youtube_link}")

        twitter_x_elements = driver.find_elements(By.XPATH, "//a[contains(@href, 'twitter.com') or contains(@href, 'x.com')]")
        print(f"[DEBUG] Twitter/X Elements Found: {len(twitter_x_elements)}")
        twitter_x_link = twitter_x_elements[0].get_attribute("href") if twitter_x_elements else None
        print(f"[DEBUG] Twitter/X Link: {twitter_x_link}")

        linktree_elements = driver.find_elements(By.XPATH, "//a[contains(@href, 'linktr.ee')]")
        print(f"[DEBUG] Linktree Elements Found: {len(linktree_elements)}")
        linktree_link = linktree_elements[0].get_attribute("href") if linktree_elements else None
        print(f"[DEBUG] Linktree Link: {linktree_link}")

        behance_elements = driver.find_elements(By.XPATH, "//a[contains(@href, 'behance.net')]")
        print(f"[DEBUG] Behance Elements Found: {len(behance_elements)}")
        behance_link = behance_elements[0].get_attribute("href") if behance_elements else None
        print(f"[DEBUG] Behance Link: {behance_link}")

        medium_elements = driver.find_elements(By.XPATH, "//a[contains(@href, 'medium.com')]")
        print(f"[DEBUG] Medium Elements Found: {len(medium_elements)}")
        medium_link = medium_elements[0].get_attribute("href") if medium_elements else None
        print(f"[DEBUG] Medium Link: {medium_link}")

        discord_elements = driver.find_elements(By.XPATH, "//a[contains(@href, 'discord.gg') or contains(@href, 'discord.com')]")
        print(f"[DEBUG] Discord Elements Found: {len(discord_elements)}")
        discord_link = discord_elements[0].get_attribute("href") if discord_elements else None
        print(f"[DEBUG] Discord Link: {discord_link}")

        telegram_elements = driver.find_elements(By.XPATH, "//a[contains(@href, 't.me')]")
        print(f"[DEBUG] Telegram Elements Found: {len(telegram_elements)}")
        telegram_link = telegram_elements[0].get_attribute("href") if telegram_elements else None
        print(f"[DEBUG] Telegram Link: {telegram_link}")

        reddit_elements = driver.find_elements(By.XPATH, "//a[contains(@href, 'reddit.com')]")
        print(f"[DEBUG] Reddit Elements Found: {len(reddit_elements)}")
        reddit_link = reddit_elements[0].get_attribute("href") if reddit_elements else None
        print(f"[DEBUG] Reddit Link: {reddit_link}")

        soundcloud_elements = driver.find_elements(By.XPATH, "//a[contains(@href, 'soundcloud.com')]")
        print(f"[DEBUG] SoundCloud Elements Found: {len(soundcloud_elements)}")
        soundcloud_link = soundcloud_elements[0].get_attribute("href") if soundcloud_elements else None
        print(f"[DEBUG] SoundCloud Link: {soundcloud_link}")

        github_elements = driver.find_elements(By.XPATH, "//a[contains(@href, 'github.com')]")
        print(f"[DEBUG] GitHub Elements Found: {len(github_elements)}")
        github_link = github_elements[0].get_attribute("href") if github_elements else None
        print(f"[DEBUG] GitHub Link: {github_link}")

        tiktok_elements = driver.find_elements(By.XPATH, "//a[contains(@href, 'tiktok.com')]")
        print(f"[DEBUG] TikTok Elements Found: {len(tiktok_elements)}")
        tiktok_link = tiktok_elements[0].get_attribute("href") if tiktok_elements else None
        print(f"[DEBUG] Tiktok Link: {tiktok_link}")

        Vercel_elements = driver.find_elements(By.XPATH, "//a[contains(@href, 'vercel.app')]")
        print(f"[DEBUG] Vercel Elements Found: {len(Vercel_elements)}")
        Vercel_link = Vercel_elements[0].get_attribute("href") if Vercel_elements else None
        print(f"[DEBUG] Vercel Link: {Vercel_link}")

        PlayerDuo_elements = driver.find_elements(By.XPATH, "//a[contains(@href, 'playerduo.com')]")
        print(f"[DEBUG] PlayerDuo Elements Found: {len(PlayerDuo_elements)}")
        PlayerDuo_link = PlayerDuo_elements[0].get_attribute("href") if PlayerDuo_elements else None
        print(f"[DEBUG] PlayerDuo Link: {PlayerDuo_link}")

        Threads_elements = driver.find_elements(By.XPATH, "//a[contains(@href, 'threads.net')]")
        print(f"[DEBUG] Threads Elements Found: {len(Threads_elements)}")
        Threads_link = Threads_elements[0].get_attribute("href") if Threads_elements else None
        print(f"[DEBUG] Thread Link: {Threads_link}")

        Spotify_elements = driver.find_elements(By.XPATH, "//a[contains(@href, 'open.spotify.com')]")
        print(f"[DEBUG] Spotify Elements Found: {len(Spotify_elements)}")
        Spotify_link = Spotify_elements[0].get_attribute("href") if Spotify_elements else None
        print(f"[DEBUG] Spotify Link: {Spotify_link}")

        friends_count = 0
        try:
            friends_element = driver.find_element(By.XPATH, "//a[contains(@href, 'friends')]")
            friends_text = friends_element.get_attribute("innerText")
            friends_count = int(''.join(filter(str.isdigit, friends_text))) if friends_text else 0
        except:
            pass
        
        friends_count = 0
        try:
            friends_element = driver.find_element(By.XPATH, "//a[contains(@href, '/friends/') and (contains(normalize-space(.), 'friends') or contains(normalize-space(.), 'ng∆∞·ªùi b·∫°n'))]")
            friends_text = friends_element.get_attribute("innerText")
            friends_count = int(''.join(filter(str.isdigit, friends_text))) if friends_text else 0
        except:
            pass 

        posts = driver.find_elements(By.XPATH, "//div[@role='article']")
        posts_count = len(posts)
        
        avatar_element = driver.find_elements(By.XPATH, "//img[contains(@src, 'https://')]")
        has_avatar = bool(avatar_element)
        avatar_blurry = check_blur(avatar_element[0].get_attribute("src")) if has_avatar else False
        
        has_custom_url = "profile.php?id=" not in url
        has_name_changes = "changed their name" in driver.page_source
        reported_spam = "reported this account" in driver.page_source
        flagged_by_fb = "Your account has been flagged" in driver.page_source
        
        
        
        # Kh·ªüi t·∫°o score
        score = 0

        
        

        # Ti·∫øp t·ª•c c·ªông c√°c ƒëi·ªÉm kh√°c (lu√¥n ch·∫°y, n·∫±m chung m·ª©c indent v·ªõi if/else ·ªü tr√™n)
        score += 5 if details["Mutualfriends"] else 0
        score += 10 if details["HasStories"] else 0
        score += 5 if details["Work"] else 0
        score += 5 if details["Lives"] else 0
        score += 5 if details["Goes_to"] else 0
        score += 5 if details["Studied"] else 0
        score += 10 if details["Relationship"] else 0
        score += 5 if details["Birthday"] else 0
        score += 5 if details["Checkins"] else 0
        score += 5 if details["Followed by"] else 0
        score += 5 if details["following"] else 0
        score += 5 if details["followers"] else 0
        score += 5 if details["From"] else 0
        score += 5 if details["Manager_at"] else 0
        score += 5 if details["Joined_on"] else 0
        score += 5 if details["Chu_tich_at"] else 0
        score += 5 if details["T√¥ng_giam_ƒë√¥c_at"] else 0
        score += 20 if posts_count >= 3 else -10
        score += 5 if details["Went_to"] else 0
        score += 20 if friends_count > 100 else 0
        score += 5 if has_avatar else -10
        score += 5 if not avatar_blurry else 0
        score += 10 if details["Email_verified"] else 0
        score += 10 if details["Phone_verified"] else 0
        score += 10 if details["Instagram"] else 0
        score += 30 if has_custom_url else -20
        score += 5 if not has_name_changes else -15
        score += 5 if not reported_spam else -20
        score += 5 if not flagged_by_fb else -25
        score += 10 if github_link else 0
        score += 10 if tiktok_link else 0
        score += 10 if Vercel_link else 0
        score += 10 if PlayerDuo_link else 0
        score += 10 if Threads_link else 0
        score += 10 if Spotify_link else 0
        score += 10 if youtube_link else 0
        score += 10 if twitter_x_link else 0
        score += 10 if linktree_link else 0
        score += 10 if behance_link else 0
        score += 10 if medium_link else 0
        score += 10 if discord_link else 0
        score += 10 if telegram_link else 0
        score += 10 if reddit_link else 0
        score += 10 if soundcloud_link else 0
        


        photo_count = count_photos(driver)

        print(f"[INFO] S·ªë ·∫£nh: {photo_count}")
        score += 10 if photo_count >= 5 else 0
        print(f"[INFO] Account Details: {json.dumps({**{k: int(v) for k, v in details.items()}, 'name': name, 'friends': friends_count, 'posts': posts_count, 'avatar': int(has_avatar), 'blurry_avatar': int(avatar_blurry), 'score': score,**details, 'github_link': github_link}, indent=4, ensure_ascii=False)}")

        
        return {
    "url": url,
    "name": name,
    "locked_profile": False,
    "score": score
}

    except Exception as e:
        print(f"[ERROR] Failed to check {url}: {e}")
        return None
def process_accounts(input_file, output_file):
    driver = webdriver.Chrome(service=service, options=chrome_options)
    
    # ƒêƒÉng nh·∫≠p v√†o Facebook b·∫±ng cookie
    if not login_with_cookies(driver, "https://www.facebook.com"):
        driver.quit()
        return

    urls = read_accounts_from_excel(input_file)
    results = []

    for url in urls:
        print(f"üîç Checking account: {url}...")
        data = check_account(driver, url)
        if data:
            results.append(data)
    
    driver.quit()

    # L∆∞u k·∫øt qu·∫£ ra file Excel
    if results:
        df_results = pd.DataFrame(results)
        df_filtered = df_results[df_results["score"] >= 70]  # L·ªçc t√†i kho·∫£n ƒë√°ng tin c·∫≠y

        if not os.path.exists(output_file):
            df_filtered.to_excel(output_file, index=False)
        else:
            existing_df = pd.read_excel(output_file)
            df_combined = pd.concat([existing_df, df_filtered], ignore_index=True).drop_duplicates()
            df_combined.to_excel(output_file, index=False)

        print(f"‚úÖ Results saved to {output_file} - Trusted accounts: {len(df_filtered)}")

if __name__ == "__main__":
    process_accounts("testclone.xlsx", "filtered_accounts.xlsx")